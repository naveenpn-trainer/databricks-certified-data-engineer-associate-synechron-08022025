# Apache Spark

> Apache Spark is an **in-memory cluster computing framework** designed to handle a wide range of big data workloads.

1. Data Integration and ETL
2. High Performance Batch Computation
3. Machine learning analytics
4. Real-time streaming processing

**Important Points**

* Apache Spark is natively written using Scala Programming.
* Spark is built on top of MapReduce

## What is PySpark

> PySpark is the Python API for Apache Spark (Distributed Processing Framework)

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdW4uh7W_1_d-2-LmLYzsjeUVHSfl5uo1j_oIACDi6K55zH638Mk29r6miatLmksg0eXdw5r3QJfla3vvYXPWcOnUTpn4Alixh_NgMtMDzV__dWgRr3CDhSSw4WddkWuxcpUrXEHFBuDrQiq7fpZgcGw7qP?key=_he-T4Jq934AhrSZa-Be-g)



## Spark Eco system

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXd3WUS2pB0UepDmqVs0Fj6ZV5BZBQz4SgPVwa5vdHT9_fJLZnR5f5QgxFCKEdH4Ocfo3Y_lzq_EYoq53BOTznNuTbFfQ5aa49tCWr_UVXG3WMBOp0khwbu0N9ersPVoFK8dKXXupQIouCrGnPDcqmiYyLOc?key=_he-T4Jq934AhrSZa-Be-g)



## Building a Spark Application

1. Load the data
2. Process the data
3. Write the results to different destination

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXddWzVdCoN7Pib1u5I_OxPWKvpUcsJbYQFvgsCa2yyzoO_nWFGDPAxWddgJKus_cYB2zZKaNYqEFTEUXhvfVXsRXtsdj65QQpV8zPiMp6rBCG2WP7gJP5W3sO88gGCBsEeOkhgmOKRbRqeWjW-8awmWaeQ?key=_he-T4Jq934AhrSZa-Be-g)



## RDD's 

> RDD (Resilient Distributed Dataset) which are the building blocks of any spark application, a fundamental data structure in Apache Spark

* It is deprecated



## Partitions

RDD's is a collection of objects that is partitioned and distributed across nodes in a cluster

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXekIxpgoiRcyLUylUzokf4jquOPTyEizuutWbGEZALMcqlVrsqs8e3QMvO6gMY90dcgoAnL2Zej57yXx9L3-WCJBXUelX2cpKa_fztxFq1AoL9BknnESa6yESoOgBtAS1v88LG2Cdi4aFydkVLzEc474e8F?key=Dxp7lTxgvspH2ig-I7LuEw)





## Spark Interactive Shell

1. Spark Shell (Scala Programming)
2. PySpark Shell (Python Programming)

## RDD Creation

There are two popular ways to create an RDD

1. Create an RDD from collection
2. Create an RDD from external source

## Operations on RDD

1. Transformation
2. Actions

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXd4zRFKjDCaWEOC1oV_-2zlstGqXLDD9YaXIwXekGa7VM5R2mNZXB0hjeqb0WfuL24OgofDS3RzP6Fgl9kiG7A5WH3H9I17Qq0jc_k0gPU34r-C1StnG6QXpdmg3Dg32_Gv077nQqaF3uO4U6qAAKpKerE7?key=Dxp7lTxgvspH2ig-I7LuEw)

















